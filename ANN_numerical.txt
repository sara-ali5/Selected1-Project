import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder


data = pd.read_csv("G:\ml sections\dataset.csv")
#handle non and garbege value 
data['workclass'] =data['workclass'].replace(' ?',"unknown")
data['occupation'] =data['occupation'].replace(' ?',"unknown")
data['place'] =data['place'].replace(' ?',"unknown")


LE1 = LabelEncoder()
X = data.iloc[:,0:-1].values
Y = data.iloc[:,-1].values



transformers=[('encoder',OneHotEncoder(sparse=False,drop='first'),[1,2,3,4,5,6,8])]
ct =ColumnTransformer(transformers,remainder ="passthrough")
X = np.array(ct.fit_transform(X))
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
ann = tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dense(units=6,activation="relu"))
ann.add(tf.keras.layers.Dense(units=6,activation="relu"))
ann.add(tf.keras.layers.Dense(units=1,activation="sigmoid"))
ann.compile(optimizer="adam",loss="binary_crossentropy",metrics=['accuracy'])
ann.fit(X_train,Y_train,batch_size=32,epochs = 100)

